{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Course: Deep Learning\n",
        "#Program: MBA Tech AI\n",
        "#Sem: V\n",
        "# Academic Year: 2023-24\n",
        "# Instructor: Dr.Radhika Chapaneri\n",
        "# Experiment No: 5\n",
        "\n",
        "#Roll No: R046\n",
        "#Name: Tungishsanjay Sankar\n",
        "#Batch : B2\n",
        "#Date of Experiment: 14-09-2023\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YR45fKIrk-Ud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Networks\n",
        "\n"
      ],
      "metadata": {
        "id": "tVTpDOQdGOFB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWiO7dF9E1eZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the fashion-mnist pre-shuffled train data and test data\n",
        "(X_train, Y_train), (X_test,Y_test) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUQhlz5gWCyT",
        "outputId": "42577ee2-fd61-4938-a80a-28d52e25e923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmXL7ONSWXFO",
        "outputId": "cb3a7fe1-fb28-4ca7-f6b5-e41286d12991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_rows, img_cols = 28,28"
      ],
      "metadata": {
        "id": "PKGVR9mYWjQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MLP\n",
        "X_train_mlp = X_train.reshape(X_train.shape[0],img_rows*img_cols)\n",
        "Y_train_mlp_1 = Y_train"
      ],
      "metadata": {
        "id": "vViVRagpWox4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_mlp = X_test.reshape(X_test.shape[0],img_rows*img_cols)\n",
        "Y_test_mlp_1 = Y_test"
      ],
      "metadata": {
        "id": "vZbAWJcWXFLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_mlp.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-p2LLLNXUxB",
        "outputId": "25208a09-2120-4998-8d38-7da391b1f0f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train shape:\", X_train.shape, \"Y_train shape:\", Y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W35MkeyaXarq",
        "outputId": "b15d3f1c-f24a-427a-fcee-3828671870f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (60000, 28, 28) Y_train shape: (60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist_labels = [\"T-shirt/top\", #index 0\n",
        "                        \"Trouser\",\n",
        "                        \"Pullover\",\n",
        "                        \"Dress\",\n",
        "                        \"Coat\",\n",
        "                        \"Sandal\",\n",
        "                        \"Shirt\",\n",
        "                        \"Sneaker\",\n",
        "                        \"Bag\",\n",
        "                        \"Ankle boot\"]\n"
      ],
      "metadata": {
        "id": "QtaYX-dvXrVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_mlp = X_train_mlp.astype('float32')\n",
        "X_test_mlp = X_test_mlp.astype('float32')\n",
        "X_train_mlp /= 255\n",
        "X_test_mlp /=255"
      ],
      "metadata": {
        "id": "vLEEORCRYZdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_mlp[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJggDnESZQso",
        "outputId": "cec156fa-1788-4ea7-fbb0-050cb55fa2ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.00392157, 0.        , 0.        , 0.05098039,\n",
              "       0.28627452, 0.        , 0.        , 0.00392157, 0.01568628,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "       0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.01176471,\n",
              "       0.        , 0.14117648, 0.53333336, 0.49803922, 0.24313726,\n",
              "       0.21176471, 0.        , 0.        , 0.        , 0.00392157,\n",
              "       0.01176471, 0.01568628, 0.        , 0.        , 0.01176471,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
              "       0.8       , 0.6901961 , 0.5254902 , 0.5647059 , 0.48235294,\n",
              "       0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.04705882, 0.03921569, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.60784316, 0.9254902 , 0.8117647 ,\n",
              "       0.69803923, 0.41960785, 0.6117647 , 0.6313726 , 0.42745098,\n",
              "       0.2509804 , 0.09019608, 0.3019608 , 0.50980395, 0.28235295,\n",
              "       0.05882353, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.00392157, 0.        , 0.27058825,\n",
              "       0.8117647 , 0.8745098 , 0.85490197, 0.84705883, 0.84705883,\n",
              "       0.6392157 , 0.49803922, 0.4745098 , 0.47843137, 0.57254905,\n",
              "       0.5529412 , 0.34509805, 0.6745098 , 0.25882354, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.00392157, 0.00392157,\n",
              "       0.00392157, 0.        , 0.78431374, 0.9098039 , 0.9098039 ,\n",
              "       0.9137255 , 0.8980392 , 0.8745098 , 0.8745098 , 0.84313726,\n",
              "       0.8352941 , 0.6431373 , 0.49803922, 0.48235294, 0.76862746,\n",
              "       0.8980392 , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.7176471 , 0.88235295, 0.84705883, 0.8745098 , 0.89411765,\n",
              "       0.92156863, 0.8901961 , 0.8784314 , 0.87058824, 0.8784314 ,\n",
              "       0.8666667 , 0.8745098 , 0.9607843 , 0.6784314 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.75686276, 0.89411765,\n",
              "       0.85490197, 0.8352941 , 0.7764706 , 0.7058824 , 0.83137256,\n",
              "       0.8235294 , 0.827451  , 0.8352941 , 0.8745098 , 0.8627451 ,\n",
              "       0.9529412 , 0.7921569 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.00392157, 0.01176471, 0.        ,\n",
              "       0.04705882, 0.85882354, 0.8627451 , 0.83137256, 0.85490197,\n",
              "       0.7529412 , 0.6627451 , 0.8901961 , 0.8156863 , 0.85490197,\n",
              "       0.8784314 , 0.83137256, 0.8862745 , 0.77254903, 0.81960785,\n",
              "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.02352941, 0.        , 0.3882353 , 0.95686275,\n",
              "       0.87058824, 0.8627451 , 0.85490197, 0.79607844, 0.7764706 ,\n",
              "       0.8666667 , 0.84313726, 0.8352941 , 0.87058824, 0.8627451 ,\n",
              "       0.9607843 , 0.46666667, 0.654902  , 0.21960784, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.01568628, 0.        ,\n",
              "       0.        , 0.21568628, 0.9254902 , 0.89411765, 0.9019608 ,\n",
              "       0.89411765, 0.9411765 , 0.9098039 , 0.8352941 , 0.85490197,\n",
              "       0.8745098 , 0.91764706, 0.8509804 , 0.8509804 , 0.81960785,\n",
              "       0.36078432, 0.        , 0.        , 0.        , 0.00392157,\n",
              "       0.01568628, 0.02352941, 0.02745098, 0.00784314, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.92941177,\n",
              "       0.8862745 , 0.8509804 , 0.8745098 , 0.87058824, 0.85882354,\n",
              "       0.87058824, 0.8666667 , 0.84705883, 0.8745098 , 0.8980392 ,\n",
              "       0.84313726, 0.85490197, 1.        , 0.3019608 , 0.        ,\n",
              "       0.        , 0.01176471, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.24313726,\n",
              "       0.5686275 , 0.8       , 0.89411765, 0.8117647 , 0.8352941 ,\n",
              "       0.8666667 , 0.85490197, 0.8156863 , 0.827451  , 0.85490197,\n",
              "       0.8784314 , 0.8745098 , 0.85882354, 0.84313726, 0.8784314 ,\n",
              "       0.95686275, 0.62352943, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.07058824, 0.17254902, 0.32156864,\n",
              "       0.41960785, 0.7411765 , 0.89411765, 0.8627451 , 0.87058824,\n",
              "       0.8509804 , 0.8862745 , 0.78431374, 0.8039216 , 0.827451  ,\n",
              "       0.9019608 , 0.8784314 , 0.91764706, 0.6901961 , 0.7372549 ,\n",
              "       0.98039216, 0.972549  , 0.9137255 , 0.93333334, 0.84313726,\n",
              "       0.        , 0.        , 0.22352941, 0.73333335, 0.8156863 ,\n",
              "       0.8784314 , 0.8666667 , 0.8784314 , 0.8156863 , 0.8       ,\n",
              "       0.8392157 , 0.8156863 , 0.81960785, 0.78431374, 0.62352943,\n",
              "       0.9607843 , 0.75686276, 0.80784315, 0.8745098 , 1.        ,\n",
              "       1.        , 0.8666667 , 0.91764706, 0.8666667 , 0.827451  ,\n",
              "       0.8627451 , 0.9098039 , 0.9647059 , 0.        , 0.01176471,\n",
              "       0.7921569 , 0.89411765, 0.8784314 , 0.8666667 , 0.827451  ,\n",
              "       0.827451  , 0.8392157 , 0.8039216 , 0.8039216 , 0.8039216 ,\n",
              "       0.8627451 , 0.9411765 , 0.3137255 , 0.5882353 , 1.        ,\n",
              "       0.8980392 , 0.8666667 , 0.7372549 , 0.6039216 , 0.7490196 ,\n",
              "       0.8235294 , 0.8       , 0.81960785, 0.87058824, 0.89411765,\n",
              "       0.88235295, 0.        , 0.38431373, 0.9137255 , 0.7764706 ,\n",
              "       0.8235294 , 0.87058824, 0.8980392 , 0.8980392 , 0.91764706,\n",
              "       0.9764706 , 0.8627451 , 0.7607843 , 0.84313726, 0.8509804 ,\n",
              "       0.94509804, 0.25490198, 0.28627452, 0.41568628, 0.45882353,\n",
              "       0.65882355, 0.85882354, 0.8666667 , 0.84313726, 0.8509804 ,\n",
              "       0.8745098 , 0.8745098 , 0.8784314 , 0.8980392 , 0.11372549,\n",
              "       0.29411766, 0.8       , 0.83137256, 0.8       , 0.75686276,\n",
              "       0.8039216 , 0.827451  , 0.88235295, 0.84705883, 0.7254902 ,\n",
              "       0.77254903, 0.80784315, 0.7764706 , 0.8352941 , 0.9411765 ,\n",
              "       0.7647059 , 0.8901961 , 0.9607843 , 0.9372549 , 0.8745098 ,\n",
              "       0.85490197, 0.83137256, 0.81960785, 0.87058824, 0.8627451 ,\n",
              "       0.8666667 , 0.9019608 , 0.2627451 , 0.1882353 , 0.79607844,\n",
              "       0.7176471 , 0.7607843 , 0.8352941 , 0.77254903, 0.7254902 ,\n",
              "       0.74509805, 0.7607843 , 0.7529412 , 0.7921569 , 0.8392157 ,\n",
              "       0.85882354, 0.8666667 , 0.8627451 , 0.9254902 , 0.88235295,\n",
              "       0.84705883, 0.78039217, 0.80784315, 0.7294118 , 0.70980394,\n",
              "       0.69411767, 0.6745098 , 0.70980394, 0.8039216 , 0.80784315,\n",
              "       0.4509804 , 0.        , 0.47843137, 0.85882354, 0.75686276,\n",
              "       0.7019608 , 0.67058825, 0.7176471 , 0.76862746, 0.8       ,\n",
              "       0.8235294 , 0.8352941 , 0.8117647 , 0.827451  , 0.8235294 ,\n",
              "       0.78431374, 0.76862746, 0.7607843 , 0.7490196 , 0.7647059 ,\n",
              "       0.7490196 , 0.7764706 , 0.7529412 , 0.6901961 , 0.6117647 ,\n",
              "       0.654902  , 0.69411767, 0.8235294 , 0.36078432, 0.        ,\n",
              "       0.        , 0.2901961 , 0.7411765 , 0.83137256, 0.7490196 ,\n",
              "       0.6862745 , 0.6745098 , 0.6862745 , 0.70980394, 0.7254902 ,\n",
              "       0.7372549 , 0.7411765 , 0.7372549 , 0.75686276, 0.7764706 ,\n",
              "       0.8       , 0.81960785, 0.8235294 , 0.8235294 , 0.827451  ,\n",
              "       0.7372549 , 0.7372549 , 0.7607843 , 0.7529412 , 0.84705883,\n",
              "       0.6666667 , 0.        , 0.00784314, 0.        , 0.        ,\n",
              "       0.        , 0.25882354, 0.78431374, 0.87058824, 0.92941177,\n",
              "       0.9372549 , 0.9490196 , 0.9647059 , 0.9529412 , 0.95686275,\n",
              "       0.8666667 , 0.8627451 , 0.75686276, 0.7490196 , 0.7019608 ,\n",
              "       0.7137255 , 0.7137255 , 0.70980394, 0.6901961 , 0.6509804 ,\n",
              "       0.65882355, 0.3882353 , 0.22745098, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n",
              "       0.28235295, 0.16078432, 0.13725491, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "\n",
        "Y_train_mlp = keras.utils.to_categorical(Y_train_mlp_1, num_classes)\n",
        "\n",
        "Y_test_mlp = keras.utils.to_categorical(Y_test_mlp_1, num_classes)"
      ],
      "metadata": {
        "id": "k3rHR5imZS4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_mlp[:5,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbIl0xLSZqEW",
        "outputId": "1dc0c699-1a74-45ce-b9be-5423303378f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_mlp, X_val_mlp, Y_train_mlp, Y_val_mlp = train_test_split(X_train_mlp,\n",
        "                                                                  Y_train_mlp,\n",
        "                                                                  test_size=0.2)"
      ],
      "metadata": {
        "id": "ii9a00vHZtDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_mlp.shape)\n",
        "print(X_val_mlp.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oStbK5RCaA2k",
        "outputId": "4431a00b-410f-4848-debd-2277b9c665df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48000, 784)\n",
            "(12000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multilayer Perceptron Model"
      ],
      "metadata": {
        "id": "9x8_lNJPz05K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD\n",
        "from keras.datasets import mnist\n",
        "#from keras.utils import np_utils"
      ],
      "metadata": {
        "id": "YZ2ahP9zaMLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "BWIyhNml04zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "EvIyCuDM1Cqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(input_dim=784,activation='sigmoid',units=625,kernel_initializer='normal'))\n",
        "model.add(Dense(input_dim=625,activation='softmax',units=10,kernel_initializer='normal'))\n",
        "model.compile(optimizer=SGD(lr=0.05, momentum=0.9),loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeGHinVe1Fti",
        "outputId": "8a798cb7-720a-4ab2-9b65-3382e613ad97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmJ1B5Hr12oL",
        "outputId": "3dde5dff-8aaf-4119-f478-c0c9a0cef3b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 625)               490625    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                6260      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 496885 (1.90 MB)\n",
            "Trainable params: 496885 (1.90 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(X_train_mlp, Y_train_mlp,\n",
        "                  batch_size = batch_size,\n",
        "                  epochs = num_epochs,\n",
        "                  verbose=1, #Output after all epochs\n",
        "                  validation_data=(X_val_mlp, Y_val_mlp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_consG3t172l",
        "outputId": "367bdb73-8f79-4c80-d1fa-da77a1de8acb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "188/188 [==============================] - 6s 6ms/step - loss: 1.1955 - accuracy: 0.6419 - val_loss: 0.7942 - val_accuracy: 0.7433\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.7106 - accuracy: 0.7558 - val_loss: 0.6593 - val_accuracy: 0.7750\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6256 - accuracy: 0.7796 - val_loss: 0.6065 - val_accuracy: 0.7895\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.5774 - accuracy: 0.7972 - val_loss: 0.5625 - val_accuracy: 0.8072\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.5482 - accuracy: 0.8062 - val_loss: 0.5440 - val_accuracy: 0.8092\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5249 - accuracy: 0.8158 - val_loss: 0.5303 - val_accuracy: 0.8116\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5089 - accuracy: 0.8217 - val_loss: 0.5168 - val_accuracy: 0.8208\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4971 - accuracy: 0.8252 - val_loss: 0.4976 - val_accuracy: 0.8277\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4856 - accuracy: 0.8303 - val_loss: 0.4859 - val_accuracy: 0.8309\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4763 - accuracy: 0.8336 - val_loss: 0.4809 - val_accuracy: 0.8317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test_mlp,Y_test_mlp, verbose = 1)\n",
        "print()\n",
        "print('MLP Test Loss: ', score[0])\n",
        "print('MLP Test Accuracy: ', score[1])"
      ],
      "metadata": {
        "id": "wOdPM00w2wRu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe8b8cee-d4e5-47ab-bfb4-e2f0a1aecab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5029 - accuracy: 0.8199\n",
            "\n",
            "MLP Test Loss:  0.5028523802757263\n",
            "MLP Test Accuracy:  0.8198999762535095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Changing the Activation Function"
      ],
      "metadata": {
        "id": "ssYne8mGboPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "num_epochs = 50"
      ],
      "metadata": {
        "id": "5GZZX5O3aq4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "gy_UF-gabxWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(input_dim=784,activation='ReLU',units=625,kernel_initializer='normal'))\n",
        "model.add(Dense(input_dim=625,activation='softmax',units=10,kernel_initializer='normal'))\n",
        "model.compile(optimizer=SGD(lr=0.05),loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGEo27NybzTw",
        "outputId": "ca74a77b-c721-44ec-ccf7-14dfa38d07cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKzfSpkTb5ko",
        "outputId": "faf6a9ca-c2b4-4181-e1a9-aaceaeda8a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 625)               490625    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                6260      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 496885 (1.90 MB)\n",
            "Trainable params: 496885 (1.90 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(X_train_mlp, Y_train_mlp,\n",
        "                  batch_size = batch_size,\n",
        "                  epochs = num_epochs,\n",
        "                  verbose=1, #Output after all epochs\n",
        "                  validation_data=(X_val_mlp, Y_val_mlp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2huu4GvPb8BU",
        "outputId": "4d810112-d0a2-4310-8b07-92a365398d68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "188/188 [==============================] - 2s 5ms/step - loss: 1.2784 - accuracy: 0.6145 - val_loss: 0.9257 - val_accuracy: 0.7085\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.8231 - accuracy: 0.7364 - val_loss: 0.7632 - val_accuracy: 0.7617\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.7138 - accuracy: 0.7706 - val_loss: 0.6875 - val_accuracy: 0.7780\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6543 - accuracy: 0.7904 - val_loss: 0.6386 - val_accuracy: 0.7976\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6154 - accuracy: 0.8017 - val_loss: 0.6056 - val_accuracy: 0.8075\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5866 - accuracy: 0.8098 - val_loss: 0.5833 - val_accuracy: 0.8120\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5649 - accuracy: 0.8158 - val_loss: 0.5650 - val_accuracy: 0.8193\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.5475 - accuracy: 0.8212 - val_loss: 0.5475 - val_accuracy: 0.8220\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.5335 - accuracy: 0.8249 - val_loss: 0.5359 - val_accuracy: 0.8258\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.5216 - accuracy: 0.8276 - val_loss: 0.5251 - val_accuracy: 0.8262\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.5114 - accuracy: 0.8304 - val_loss: 0.5157 - val_accuracy: 0.8313\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5024 - accuracy: 0.8329 - val_loss: 0.5083 - val_accuracy: 0.8327\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4945 - accuracy: 0.8338 - val_loss: 0.5040 - val_accuracy: 0.8332\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4876 - accuracy: 0.8358 - val_loss: 0.4948 - val_accuracy: 0.8340\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4813 - accuracy: 0.8373 - val_loss: 0.4912 - val_accuracy: 0.8338\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4758 - accuracy: 0.8392 - val_loss: 0.4855 - val_accuracy: 0.8378\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4703 - accuracy: 0.8405 - val_loss: 0.4787 - val_accuracy: 0.8407\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4654 - accuracy: 0.8413 - val_loss: 0.4776 - val_accuracy: 0.8405\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.4611 - accuracy: 0.8431 - val_loss: 0.4721 - val_accuracy: 0.8410\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.4573 - accuracy: 0.8447 - val_loss: 0.4672 - val_accuracy: 0.8417\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.4532 - accuracy: 0.8456 - val_loss: 0.4722 - val_accuracy: 0.8407\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.4499 - accuracy: 0.8461 - val_loss: 0.4603 - val_accuracy: 0.8462\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.4459 - accuracy: 0.8471 - val_loss: 0.4574 - val_accuracy: 0.8454\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.4431 - accuracy: 0.8486 - val_loss: 0.4644 - val_accuracy: 0.8422\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.4400 - accuracy: 0.8498 - val_loss: 0.4518 - val_accuracy: 0.8486\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.4366 - accuracy: 0.8510 - val_loss: 0.4492 - val_accuracy: 0.8492\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.4341 - accuracy: 0.8510 - val_loss: 0.4479 - val_accuracy: 0.8488\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 0.4314 - accuracy: 0.8525 - val_loss: 0.4471 - val_accuracy: 0.8488\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4291 - accuracy: 0.8533 - val_loss: 0.4428 - val_accuracy: 0.8497\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4263 - accuracy: 0.8531 - val_loss: 0.4398 - val_accuracy: 0.8528\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.4247 - accuracy: 0.8538 - val_loss: 0.4392 - val_accuracy: 0.8508\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.4218 - accuracy: 0.8547 - val_loss: 0.4354 - val_accuracy: 0.8537\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.4194 - accuracy: 0.8559 - val_loss: 0.4345 - val_accuracy: 0.8527\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.4175 - accuracy: 0.8570 - val_loss: 0.4353 - val_accuracy: 0.8534\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 0.4157 - accuracy: 0.8571 - val_loss: 0.4353 - val_accuracy: 0.8538\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.4133 - accuracy: 0.8577 - val_loss: 0.4298 - val_accuracy: 0.8548\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.4111 - accuracy: 0.8581 - val_loss: 0.4327 - val_accuracy: 0.8558\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4096 - accuracy: 0.8590 - val_loss: 0.4280 - val_accuracy: 0.8570\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4076 - accuracy: 0.8582 - val_loss: 0.4268 - val_accuracy: 0.8569\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4059 - accuracy: 0.8603 - val_loss: 0.4213 - val_accuracy: 0.8577\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4038 - accuracy: 0.8602 - val_loss: 0.4220 - val_accuracy: 0.8577\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4022 - accuracy: 0.8614 - val_loss: 0.4184 - val_accuracy: 0.8595\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4010 - accuracy: 0.8613 - val_loss: 0.4178 - val_accuracy: 0.8601\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.3989 - accuracy: 0.8612 - val_loss: 0.4152 - val_accuracy: 0.8598\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3971 - accuracy: 0.8637 - val_loss: 0.4172 - val_accuracy: 0.8602\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3954 - accuracy: 0.8634 - val_loss: 0.4210 - val_accuracy: 0.8588\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3943 - accuracy: 0.8638 - val_loss: 0.4198 - val_accuracy: 0.8598\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3925 - accuracy: 0.8644 - val_loss: 0.4113 - val_accuracy: 0.8612\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3914 - accuracy: 0.8652 - val_loss: 0.4090 - val_accuracy: 0.8622\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3900 - accuracy: 0.8647 - val_loss: 0.4096 - val_accuracy: 0.8602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test_mlp,Y_test_mlp, verbose = 1)\n",
        "print()\n",
        "print('MLP Test Loss: ', score[0])\n",
        "print('MLP Test Accuracy: ', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXc0ISHwb_1R",
        "outputId": "71ff3c05-5ad3-4276-c3c8-ec605ad313e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4312 - accuracy: 0.8492\n",
            "\n",
            "MLP Test Loss:  0.43123680353164673\n",
            "MLP Test Accuracy:  0.8492000102996826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding a hidden layer"
      ],
      "metadata": {
        "id": "A2m52nDWcSmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "num_epochs = 50"
      ],
      "metadata": {
        "id": "1kDETDyScC-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "Z8LG9P_bcYx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(input_dim=784,activation='sigmoid',units=625,kernel_initializer='normal'))\n",
        "model.add(Dense(input_dim=625,activation='sigmoid',units=625,kernel_initializer='normal'))\n",
        "model.add(Dense(input_dim=625,activation='softmax',units=10,kernel_initializer='normal'))\n",
        "model.compile(optimizer=SGD(lr=0.05, momentum=0.5),loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kD-VbHtwcalo",
        "outputId": "4d289a3f-b48b-4ef3-9308-00c31e05ec42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPdDQwAycvLj",
        "outputId": "46e21d50-21c6-4e6d-a3bb-eca2b3c3582e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 625)               490625    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 625)               391250    \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                6260      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 888135 (3.39 MB)\n",
            "Trainable params: 888135 (3.39 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(X_train_mlp, Y_train_mlp,\n",
        "                  batch_size = batch_size,\n",
        "                  epochs = num_epochs,\n",
        "                  verbose=1, #Output after all epochs\n",
        "                  validation_data=(X_val_mlp, Y_val_mlp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvAh7ShycwHK",
        "outputId": "f7ede5b3-a2fe-4200-9efd-e996d25e3e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "188/188 [==============================] - 2s 6ms/step - loss: 2.2482 - accuracy: 0.2687 - val_loss: 2.1969 - val_accuracy: 0.3913\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.1433 - accuracy: 0.4508 - val_loss: 2.0888 - val_accuracy: 0.5107\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.0273 - accuracy: 0.5347 - val_loss: 1.9647 - val_accuracy: 0.5584\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 1.8929 - accuracy: 0.5755 - val_loss: 1.8211 - val_accuracy: 0.5741\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.7468 - accuracy: 0.5991 - val_loss: 1.6797 - val_accuracy: 0.6008\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.6050 - accuracy: 0.6195 - val_loss: 1.5393 - val_accuracy: 0.6421\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 1.4792 - accuracy: 0.6429 - val_loss: 1.4256 - val_accuracy: 0.6521\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 1.3734 - accuracy: 0.6581 - val_loss: 1.3302 - val_accuracy: 0.6461\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.2857 - accuracy: 0.6720 - val_loss: 1.2500 - val_accuracy: 0.6818\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 1.2126 - accuracy: 0.6821 - val_loss: 1.1841 - val_accuracy: 0.6818\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.1512 - accuracy: 0.6894 - val_loss: 1.1277 - val_accuracy: 0.6877\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 1.0986 - accuracy: 0.6973 - val_loss: 1.0804 - val_accuracy: 0.7023\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 1.0535 - accuracy: 0.7026 - val_loss: 1.0372 - val_accuracy: 0.7154\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.0136 - accuracy: 0.7083 - val_loss: 1.0014 - val_accuracy: 0.7171\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.9783 - accuracy: 0.7134 - val_loss: 0.9668 - val_accuracy: 0.7181\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.9469 - accuracy: 0.7170 - val_loss: 0.9383 - val_accuracy: 0.7164\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.9187 - accuracy: 0.7205 - val_loss: 0.9121 - val_accuracy: 0.7213\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.8933 - accuracy: 0.7242 - val_loss: 0.8877 - val_accuracy: 0.7289\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.8705 - accuracy: 0.7266 - val_loss: 0.8659 - val_accuracy: 0.7300\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.8494 - accuracy: 0.7291 - val_loss: 0.8467 - val_accuracy: 0.7333\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.8304 - accuracy: 0.7318 - val_loss: 0.8281 - val_accuracy: 0.7272\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.8132 - accuracy: 0.7337 - val_loss: 0.8130 - val_accuracy: 0.7362\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.7975 - accuracy: 0.7358 - val_loss: 0.7961 - val_accuracy: 0.7408\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.7829 - accuracy: 0.7388 - val_loss: 0.7824 - val_accuracy: 0.7385\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.7698 - accuracy: 0.7404 - val_loss: 0.7714 - val_accuracy: 0.7412\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.7578 - accuracy: 0.7411 - val_loss: 0.7579 - val_accuracy: 0.7460\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.7464 - accuracy: 0.7435 - val_loss: 0.7475 - val_accuracy: 0.7499\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.7362 - accuracy: 0.7459 - val_loss: 0.7388 - val_accuracy: 0.7492\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.7270 - accuracy: 0.7469 - val_loss: 0.7277 - val_accuracy: 0.7523\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.7183 - accuracy: 0.7480 - val_loss: 0.7191 - val_accuracy: 0.7540\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.7101 - accuracy: 0.7495 - val_loss: 0.7110 - val_accuracy: 0.7541\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.7023 - accuracy: 0.7516 - val_loss: 0.7050 - val_accuracy: 0.7525\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.6954 - accuracy: 0.7525 - val_loss: 0.6971 - val_accuracy: 0.7565\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6888 - accuracy: 0.7545 - val_loss: 0.6909 - val_accuracy: 0.7603\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.6824 - accuracy: 0.7562 - val_loss: 0.6863 - val_accuracy: 0.7581\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6765 - accuracy: 0.7571 - val_loss: 0.6785 - val_accuracy: 0.7619\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6711 - accuracy: 0.7583 - val_loss: 0.6731 - val_accuracy: 0.7632\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6656 - accuracy: 0.7598 - val_loss: 0.6693 - val_accuracy: 0.7638\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.6607 - accuracy: 0.7610 - val_loss: 0.6629 - val_accuracy: 0.7651\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6558 - accuracy: 0.7631 - val_loss: 0.6583 - val_accuracy: 0.7667\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.6511 - accuracy: 0.7640 - val_loss: 0.6547 - val_accuracy: 0.7658\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.6469 - accuracy: 0.7660 - val_loss: 0.6496 - val_accuracy: 0.7689\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.6426 - accuracy: 0.7670 - val_loss: 0.6459 - val_accuracy: 0.7677\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6384 - accuracy: 0.7677 - val_loss: 0.6409 - val_accuracy: 0.7707\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.6344 - accuracy: 0.7701 - val_loss: 0.6379 - val_accuracy: 0.7730\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.6307 - accuracy: 0.7714 - val_loss: 0.6336 - val_accuracy: 0.7725\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.6270 - accuracy: 0.7727 - val_loss: 0.6301 - val_accuracy: 0.7735\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6233 - accuracy: 0.7728 - val_loss: 0.6264 - val_accuracy: 0.7738\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6198 - accuracy: 0.7745 - val_loss: 0.6242 - val_accuracy: 0.7769\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6163 - accuracy: 0.7757 - val_loss: 0.6196 - val_accuracy: 0.7796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test_mlp,Y_test_mlp, verbose = 1)\n",
        "print()\n",
        "print('MLP Test Loss: ', score[0])\n",
        "print('MLP Test Accuracy: ', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgirZSUHc5Tw",
        "outputId": "d8d35fc9-bc0e-4b03-d64a-25f9b2c48c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6326 - accuracy: 0.7704\n",
            "\n",
            "MLP Test Loss:  0.6325649619102478\n",
            "MLP Test Accuracy:  0.7703999876976013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With ReLU and less epochs"
      ],
      "metadata": {
        "id": "Gv2k335Cib5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "num1_epochs = 25"
      ],
      "metadata": {
        "id": "is-xurwlihEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "EdoaTXF7igNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(input_dim=784,activation='ReLU',units=625,kernel_initializer='normal'))\n",
        "model.add(Dense(input_dim=625,activation='ReLU',units=625,kernel_initializer='normal'))\n",
        "model.add(Dense(input_dim=625,activation='softmax',units=10,kernel_initializer='normal'))\n",
        "model.compile(optimizer=SGD(lr=0.05, momentum=0.1),loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4Xajj2Sijn1",
        "outputId": "926a5508-5ae3-4d44-9b26-bcb489ca9287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRs-3v4DipVc",
        "outputId": "dca54867-c26c-4094-a0a3-2d69e03cb7c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_7 (Dense)             (None, 625)               490625    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 625)               391250    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                6260      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 888135 (3.39 MB)\n",
            "Trainable params: 888135 (3.39 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(X_train_mlp, Y_train_mlp,\n",
        "                  batch_size = batch_size,\n",
        "                  epochs = num1_epochs,\n",
        "                  verbose=1, #Output after all epochs\n",
        "                  validation_data=(X_val_mlp, Y_val_mlp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc74HlYBiqzH",
        "outputId": "8e5ced30-3660-424b-9ba5-2e4dd9a43821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "188/188 [==============================] - 2s 6ms/step - loss: 1.2251 - accuracy: 0.6545 - val_loss: 0.8403 - val_accuracy: 0.7405\n",
            "Epoch 2/25\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.7413 - accuracy: 0.7676 - val_loss: 0.6854 - val_accuracy: 0.7824\n",
            "Epoch 3/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.6376 - accuracy: 0.7947 - val_loss: 0.6160 - val_accuracy: 0.8035\n",
            "Epoch 4/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.5831 - accuracy: 0.8090 - val_loss: 0.5720 - val_accuracy: 0.8129\n",
            "Epoch 5/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.5480 - accuracy: 0.8184 - val_loss: 0.5442 - val_accuracy: 0.8217\n",
            "Epoch 6/25\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.5234 - accuracy: 0.8250 - val_loss: 0.5268 - val_accuracy: 0.8264\n",
            "Epoch 7/25\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.5046 - accuracy: 0.8288 - val_loss: 0.5118 - val_accuracy: 0.8278\n",
            "Epoch 8/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4902 - accuracy: 0.8338 - val_loss: 0.4980 - val_accuracy: 0.8319\n",
            "Epoch 9/25\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4778 - accuracy: 0.8365 - val_loss: 0.4867 - val_accuracy: 0.8349\n",
            "Epoch 10/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4677 - accuracy: 0.8401 - val_loss: 0.4756 - val_accuracy: 0.8394\n",
            "Epoch 11/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4590 - accuracy: 0.8420 - val_loss: 0.4826 - val_accuracy: 0.8352\n",
            "Epoch 12/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4512 - accuracy: 0.8447 - val_loss: 0.4618 - val_accuracy: 0.8439\n",
            "Epoch 13/25\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4456 - accuracy: 0.8455 - val_loss: 0.4572 - val_accuracy: 0.8437\n",
            "Epoch 14/25\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4379 - accuracy: 0.8486 - val_loss: 0.4489 - val_accuracy: 0.8487\n",
            "Epoch 15/25\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.4328 - accuracy: 0.8498 - val_loss: 0.4431 - val_accuracy: 0.8511\n",
            "Epoch 16/25\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.4289 - accuracy: 0.8514 - val_loss: 0.4426 - val_accuracy: 0.8491\n",
            "Epoch 17/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4213 - accuracy: 0.8543 - val_loss: 0.4445 - val_accuracy: 0.8494\n",
            "Epoch 18/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4176 - accuracy: 0.8551 - val_loss: 0.4434 - val_accuracy: 0.8467\n",
            "Epoch 19/25\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.4147 - accuracy: 0.8560 - val_loss: 0.4381 - val_accuracy: 0.8503\n",
            "Epoch 20/25\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.4102 - accuracy: 0.8571 - val_loss: 0.4264 - val_accuracy: 0.8558\n",
            "Epoch 21/25\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4064 - accuracy: 0.8590 - val_loss: 0.4292 - val_accuracy: 0.8543\n",
            "Epoch 22/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4031 - accuracy: 0.8601 - val_loss: 0.4232 - val_accuracy: 0.8538\n",
            "Epoch 23/25\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3986 - accuracy: 0.8617 - val_loss: 0.4346 - val_accuracy: 0.8474\n",
            "Epoch 24/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.3964 - accuracy: 0.8627 - val_loss: 0.4171 - val_accuracy: 0.8558\n",
            "Epoch 25/25\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3925 - accuracy: 0.8634 - val_loss: 0.4173 - val_accuracy: 0.8594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test_mlp,Y_test_mlp, verbose = 1)\n",
        "print()\n",
        "print('MLP Test Loss: ', score[0])\n",
        "print('MLP Test Accuracy: ', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igMFULVpjEXB",
        "outputId": "24ef5488-b580-43aa-8b68-5f4ec3802694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 7ms/step - loss: 0.4364 - accuracy: 0.8428\n",
            "\n",
            "MLP Test Loss:  0.43639710545539856\n",
            "MLP Test Accuracy:  0.8428000211715698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using all Activation function"
      ],
      "metadata": {
        "id": "tBmXmGlEkO7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "M4nE80ImkRZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(input_dim=784,activation='ReLU',units=625,kernel_initializer='normal'))\n",
        "model.add(Dense(input_dim=625,activation='sigmoid',units=625,kernel_initializer='normal'))\n",
        "model.add(Dense(input_dim=625,activation='tanh',units=625,kernel_initializer='normal'))\n",
        "model.add(Dense(input_dim=625,activation='softmax',units=10,kernel_initializer='normal'))\n",
        "model.compile(optimizer=SGD(lr=0.05),loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsjgDT2bkSFC",
        "outputId": "ebdab5fa-c526-4082-a16e-a6c74d8f0ee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybtMoFdikaGx",
        "outputId": "a805f430-6e88-49af-effc-8bb49dc4c76d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 625)               490625    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 625)               391250    \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 625)               391250    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 10)                6260      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1279385 (4.88 MB)\n",
            "Trainable params: 1279385 (4.88 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(X_train_mlp, Y_train_mlp,\n",
        "                  batch_size = batch_size,\n",
        "                  epochs = num1_epochs,\n",
        "                  verbose=1, #Output after all epochs\n",
        "                  validation_data=(X_val_mlp, Y_val_mlp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44WQbvPLkfSX",
        "outputId": "c8190684-b066-4c4b-ee9e-84fb130ff478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "188/188 [==============================] - 2s 6ms/step - loss: 1.7953 - accuracy: 0.5280 - val_loss: 1.3539 - val_accuracy: 0.6562\n",
            "Epoch 2/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 1.1238 - accuracy: 0.7060 - val_loss: 0.9710 - val_accuracy: 0.7201\n",
            "Epoch 3/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.8776 - accuracy: 0.7310 - val_loss: 0.8173 - val_accuracy: 0.7430\n",
            "Epoch 4/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.7661 - accuracy: 0.7439 - val_loss: 0.7345 - val_accuracy: 0.7556\n",
            "Epoch 5/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.7034 - accuracy: 0.7551 - val_loss: 0.6881 - val_accuracy: 0.7623\n",
            "Epoch 6/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.6622 - accuracy: 0.7648 - val_loss: 0.6526 - val_accuracy: 0.7750\n",
            "Epoch 7/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.6319 - accuracy: 0.7740 - val_loss: 0.6233 - val_accuracy: 0.7809\n",
            "Epoch 8/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.6080 - accuracy: 0.7822 - val_loss: 0.6023 - val_accuracy: 0.7883\n",
            "Epoch 9/25\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.5878 - accuracy: 0.7902 - val_loss: 0.5869 - val_accuracy: 0.7936\n",
            "Epoch 10/25\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.5711 - accuracy: 0.7965 - val_loss: 0.5687 - val_accuracy: 0.8008\n",
            "Epoch 11/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.5562 - accuracy: 0.8018 - val_loss: 0.5539 - val_accuracy: 0.8081\n",
            "Epoch 12/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.5427 - accuracy: 0.8073 - val_loss: 0.5430 - val_accuracy: 0.8116\n",
            "Epoch 13/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.5318 - accuracy: 0.8121 - val_loss: 0.5331 - val_accuracy: 0.8148\n",
            "Epoch 14/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.5215 - accuracy: 0.8158 - val_loss: 0.5252 - val_accuracy: 0.8167\n",
            "Epoch 15/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.5120 - accuracy: 0.8179 - val_loss: 0.5154 - val_accuracy: 0.8206\n",
            "Epoch 16/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.5039 - accuracy: 0.8206 - val_loss: 0.5146 - val_accuracy: 0.8186\n",
            "Epoch 17/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4968 - accuracy: 0.8244 - val_loss: 0.5041 - val_accuracy: 0.8218\n",
            "Epoch 18/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4901 - accuracy: 0.8268 - val_loss: 0.4967 - val_accuracy: 0.8262\n",
            "Epoch 19/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4840 - accuracy: 0.8288 - val_loss: 0.4890 - val_accuracy: 0.8288\n",
            "Epoch 20/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4784 - accuracy: 0.8317 - val_loss: 0.4837 - val_accuracy: 0.8302\n",
            "Epoch 21/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4732 - accuracy: 0.8336 - val_loss: 0.4817 - val_accuracy: 0.8289\n",
            "Epoch 22/25\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.4682 - accuracy: 0.8347 - val_loss: 0.4827 - val_accuracy: 0.8288\n",
            "Epoch 23/25\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.4633 - accuracy: 0.8369 - val_loss: 0.4703 - val_accuracy: 0.8342\n",
            "Epoch 24/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4589 - accuracy: 0.8389 - val_loss: 0.4694 - val_accuracy: 0.8347\n",
            "Epoch 25/25\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4553 - accuracy: 0.8399 - val_loss: 0.4659 - val_accuracy: 0.8386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test_mlp,Y_test_mlp, verbose = 1)\n",
        "print()\n",
        "print('MLP Test Loss: ', score[0])\n",
        "print('MLP Test Accuracy: ', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuTE-m4hktpx",
        "outputId": "5fac299e-e78b-4b80-b4b3-f920af24aced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4863 - accuracy: 0.8275\n",
            "\n",
            "MLP Test Loss:  0.48633822798728943\n",
            "MLP Test Accuracy:  0.8274999856948853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Jk9LTKwAtr1V"
      }
    }
  ]
}